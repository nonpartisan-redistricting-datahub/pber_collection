{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8574dd01-6131-407e-bfea-449a19154614",
   "metadata": {},
   "source": [
    "# OH 2022 PBER Cleaning\n",
    "\n",
    "## On self overlay\n",
    "The RDH received precinct shapefiles for every county in Ohio from the OpenElections team. The RDH standardized the shapefiles, made modifications where needed, and combined all of them into one statewide file to be joined with precinct-level election results. \n",
    "\n",
    "With the precinct boundary and election results geodataframe, the RDH runs maup.assign() to dissaggregate the election results down to the Census Block level from the precincts to improve the utility to map drawers. In some precincts within the original Ohio shapefile, the geometry contained an additional layer without its' own geometry. This additional layer would not be visible at a first glance, but causes a duplicate axis error when maup.assign() is run as the blocks then have two precinct layers they could be assigned to, when each should have one and only one assignment. \n",
    "\n",
    "The following code cleans the overlapping geometries so that maup can be run and the shapefile is better set for any future analyses.\n",
    "\n",
    "This code was used to develop and check the technique, but file production was completed in \"pber_only_v1.ipynb\" in order to keep the precinct processing together\n",
    "\n",
    "**Last updated 9/8/2023**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23a4a939-e670-4ec1-9553-4cc2091db27f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import maup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "\n",
    "#Step 0: Load in relevant gdfs - 2022 PBER drafts, and 2020 blocks - + fxns\n",
    "oh_blocks = gp.read_file(\"./oh_pl2020_b/oh_pl2020_p1_b.shp\")[['GEOID20','P0010001', 'geometry']]\n",
    "pber_all = gp.read_file(\"./oh_2022_gen_prec_shp_wip/oh_2022_gen_prec_no_splits.shp\") \n",
    "pber_st = gp.read_file(\"./oh_2022_gen_prec_shp_wip/oh_2022_gen_prec_st.shp\")\n",
    "pber_cong = gp.read_file(\"./oh_2022_gen_prec_shp_wip/oh_2022_gen_prec_cong.shp\")\n",
    "pber_sl = gp.read_file(\"./oh_2022_gen_prec_shp_wip/oh_2022_gen_prec_sldl.shp\")\n",
    "assert set(pber_sl[pber_sl.columns[pber_sl.columns.str.startswith(\"G\")]][pber_sl[\"UNIQUE_ID\"]=='SUMMIT-AGT-(SL-031)'].sum()[pber_sl[\n",
    "    pber_sl.columns[pber_sl.columns.str.startswith(\"G\")]][pber_sl[\"UNIQUE_ID\"]=='SUMMIT-AGT-(SL-031)'].sum()!=0]) == set()\n",
    "pber_sl = pber_sl[pber_sl[\"UNIQUE_ID\"]!='SUMMIT-AGT-(SL-031)']\n",
    "pber_su = gp.read_file(\"./oh_2022_gen_prec_shp_wip/oh_2022_gen_prec_sldu.shp\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "593c0a9d-e59e-4759-aef4-055abbe227c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_self_intersection(pber, oh_blocks):\n",
    "    #Step 1: Self intersect precinct gdf\n",
    "    self_intersect_gdf = gp.overlay(pber, pber, how=\"intersection\", keep_geom_type=False)\n",
    "\n",
    "\n",
    "    #Step 2: Filter out tiny areas from intersection as leaving them would cause future overlay issues\n",
    "    self_intersect_gdf = self_intersect_gdf[self_intersect_gdf.area>0.00001]\n",
    "\n",
    "\n",
    "    #Step 3: Filter into IDs that are equal and not equal - equal is the same as original prec gdf, not equal are tiny pieces that overlap as their own shapes\n",
    "    id1_not_id2 = self_intersect_gdf[self_intersect_gdf[\"UNIQUE_ID_1\"]!=self_intersect_gdf[\"UNIQUE_ID_2\"]]\n",
    "    id1_is_id2 = self_intersect_gdf[self_intersect_gdf[\"UNIQUE_ID_1\"]==self_intersect_gdf[\"UNIQUE_ID_2\"]]\n",
    "\n",
    "\n",
    "    #Step 4: Overlay tiny pieces with blocks to see which are actually problematic for maup\n",
    "    assert oh_blocks.crs == id1_not_id2.crs\n",
    "    block_tiny_id_overlay = gp.overlay(oh_blocks, id1_not_id2, how=\"intersection\", keep_geom_type=False)\n",
    "\n",
    "\n",
    "    #Step 5: Grab precinct names for area > 0.00001 from block tiny piece intersection as only area less than this will not cause problems\n",
    "    set_prec_to_change = set(block_tiny_id_overlay[\"UNIQUE_ID_1\"][block_tiny_id_overlay.area>0.00001])\n",
    "\n",
    "\n",
    "    #Step 6: Filter id1_not_id2 to just include set_prec_to_change\n",
    "    gdf_to_pull_out = id1_not_id2[id1_not_id2[\"UNIQUE_ID_1\"].isin(set_prec_to_change)]\n",
    "\n",
    "\n",
    "    #Step 7: Run symmetric difference of prec_gdf with gdf_to_pull_out\n",
    "    assert pber.crs == gdf_to_pull_out.crs\n",
    "    try:\n",
    "        overlaps_removed = gp.overlay(pber, gdf_to_pull_out, how=\"symmetric_difference\", keep_geom_type=False)\n",
    "    except:\n",
    "        gdf_to_pull_out_mod = remove_bad_geom(gdf_to_pull_out)\n",
    "        overlaps_removed = gp.overlay(pber, gdf_to_pull_out_mod, how=\"symmetric_difference\", keep_geom_type=False)\n",
    "\n",
    "    \n",
    "    #Step 8: Add missing precinct back in and cut out bad ones\n",
    "    pber_updated = gp.GeoDataFrame(pd.concat([overlaps_removed, pber[pber[\"UNIQUE_ID\"]=='ERIE-PRECINCT CAST VILL'],pber[pber[\"UNIQUE_ID\"]=='WOOD-PERRYSBURG J']], ignore_index=True), crs = overlaps_removed.crs)\n",
    "    pber_updated = pber_updated[~pber_updated[\"UNIQUE_ID\"].isna()]\n",
    "    pber_updated = remove_bad_geom(pber_updated)\n",
    "    #try:\n",
    "     #   assert pber_updated[\"UNIQUE_ID\"].nunique() == pber[\"UNIQUE_ID\"].nunique()\n",
    "    #except:\n",
    "    pber_updated = pber_updated.dissolve(by=\"UNIQUE_ID\").reset_index()\n",
    "\n",
    "    return pber_updated\n",
    "\n",
    "\n",
    "def remove_bad_geom(gdf):\n",
    "    #Step 9: Remove bad geom\n",
    "    geom_as_string = gdf[\"geometry\"].astype(str)\n",
    "    bad_geom = geom_as_string[geom_as_string.apply(lambda x: x.startswith(\"GEOMETRYCOLLECTION\"))]\n",
    "    gdf_updated = gdf[~gdf.index.isin(set(bad_geom.index))]\n",
    "    \n",
    "    return gdf_updated\n",
    "\n",
    "\n",
    "def fix_buffer(gdf):\n",
    "    \"\"\"\n",
    "    return (GeoDataFrame) with the 'buffer(0) trick' applied\n",
    "    :gdf: (GeoDataFrame) object\n",
    "    Can be useful when trying to mitigate 'self-intersection' issues\n",
    "    \"\"\"\n",
    "    buffered = gdf.buffer(0)\n",
    "    gdf.drop(columns=[\"geometry\"])\n",
    "    # gdf['geometry'] = gdf.apply(lambda x: x.geometry.buffer(0), axis=1)\n",
    "    gdf[\"geometry\"] = buffered\n",
    "    \n",
    "    return gdf\n",
    "\n",
    "\n",
    "def export_import_test(pber, pber_updated, oh_blocks):\n",
    "    #Step 10: Test Results\n",
    "    assert pber_updated[\"UNIQUE_ID\"].nunique() == pber[\"UNIQUE_ID\"].nunique()\n",
    "    pber_updated.to_file(\"./oh_2022_gen_prec_shp_wip/test_export_import.shp\")\n",
    "    pber_test_import = gp.read_file(\"./oh_2022_gen_prec_shp_wip/test_export_import.shp\")\n",
    "    maup_test_import = maup.assign(fix_buffer(oh_blocks),fix_buffer(pber_test_import))\n",
    "    \n",
    "    return maup_test_import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bce3835-0e97-4a1a-b827-30847f308e80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-0326f1434f7a>:7: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  self_intersect_gdf = self_intersect_gdf[self_intersect_gdf.area>0.00001]\n",
      "<ipython-input-2-0326f1434f7a>:21: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  set_prec_to_change = set(block_tiny_id_overlay[\"UNIQUE_ID_1\"][block_tiny_id_overlay.area>0.00001])\n",
      "/Users/lilyfalk/anaconda3/envs/pdv_env/lib/python3.9/site-packages/maup/intersections.py:42: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  geometries = geometries[geometries.area > area_cutoff]\n",
      "/Users/lilyfalk/anaconda3/envs/pdv_env/lib/python3.9/site-packages/maup/assign.py:26: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  return assign_to_max(intersections(sources, targets, area_cutoff=0).area)\n",
      "<ipython-input-2-0326f1434f7a>:7: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  self_intersect_gdf = self_intersect_gdf[self_intersect_gdf.area>0.00001]\n",
      "<ipython-input-2-0326f1434f7a>:21: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  set_prec_to_change = set(block_tiny_id_overlay[\"UNIQUE_ID_1\"][block_tiny_id_overlay.area>0.00001])\n",
      "/Users/lilyfalk/anaconda3/envs/pdv_env/lib/python3.9/site-packages/maup/intersections.py:42: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  geometries = geometries[geometries.area > area_cutoff]\n",
      "/Users/lilyfalk/anaconda3/envs/pdv_env/lib/python3.9/site-packages/maup/assign.py:26: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  return assign_to_max(intersections(sources, targets, area_cutoff=0).area)\n",
      "<ipython-input-2-0326f1434f7a>:7: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  self_intersect_gdf = self_intersect_gdf[self_intersect_gdf.area>0.00001]\n",
      "<ipython-input-2-0326f1434f7a>:21: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  set_prec_to_change = set(block_tiny_id_overlay[\"UNIQUE_ID_1\"][block_tiny_id_overlay.area>0.00001])\n",
      "TopologyException: found non-noded intersection between LINESTRING (-82.69 41.4916, -82.69 41.4916) and LINESTRING (-82.6899 41.4916, -82.69 41.4916) at -82.689968319949315 41.491598693991584\n",
      "/Users/lilyfalk/anaconda3/envs/pdv_env/lib/python3.9/site-packages/maup/intersections.py:42: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  geometries = geometries[geometries.area > area_cutoff]\n",
      "/Users/lilyfalk/anaconda3/envs/pdv_env/lib/python3.9/site-packages/maup/assign.py:26: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  return assign_to_max(intersections(sources, targets, area_cutoff=0).area)\n",
      "<ipython-input-2-0326f1434f7a>:7: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  self_intersect_gdf = self_intersect_gdf[self_intersect_gdf.area>0.00001]\n",
      "<ipython-input-2-0326f1434f7a>:21: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  set_prec_to_change = set(block_tiny_id_overlay[\"UNIQUE_ID_1\"][block_tiny_id_overlay.area>0.00001])\n",
      "TopologyException: found non-noded intersection between LINESTRING (-82.69 41.4916, -82.69 41.4916) and LINESTRING (-82.6899 41.4916, -82.69 41.4916) at -82.689968319949315 41.491598693991584\n",
      "/Users/lilyfalk/anaconda3/envs/pdv_env/lib/python3.9/site-packages/maup/intersections.py:42: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  geometries = geometries[geometries.area > area_cutoff]\n",
      "/Users/lilyfalk/anaconda3/envs/pdv_env/lib/python3.9/site-packages/maup/assign.py:26: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  return assign_to_max(intersections(sources, targets, area_cutoff=0).area)\n",
      "<ipython-input-2-0326f1434f7a>:7: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  self_intersect_gdf = self_intersect_gdf[self_intersect_gdf.area>0.00001]\n",
      "<ipython-input-2-0326f1434f7a>:21: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  set_prec_to_change = set(block_tiny_id_overlay[\"UNIQUE_ID_1\"][block_tiny_id_overlay.area>0.00001])\n",
      "TopologyException: found non-noded intersection between LINESTRING (-82.69 41.4916, -82.69 41.4916) and LINESTRING (-82.6899 41.4916, -82.69 41.4916) at -82.689968319949315 41.491598693991584\n",
      "/Users/lilyfalk/anaconda3/envs/pdv_env/lib/python3.9/site-packages/maup/intersections.py:42: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  geometries = geometries[geometries.area > area_cutoff]\n",
      "/Users/lilyfalk/anaconda3/envs/pdv_env/lib/python3.9/site-packages/maup/assign.py:26: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  return assign_to_max(intersections(sources, targets, area_cutoff=0).area)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         3948.0\n",
       "1         3905.0\n",
       "2         4339.0\n",
       "3         4354.0\n",
       "4         4403.0\n",
       "           ...  \n",
       "276423    1167.0\n",
       "276424    1160.0\n",
       "276425    1164.0\n",
       "276426    1166.0\n",
       "276427    1154.0\n",
       "Length: 276428, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 11: Apply\n",
    "#NO SPLITS\n",
    "pber_all_updated = fix_self_intersection(pber_all, oh_blocks)\n",
    "pber_all_format = pber_all_updated[['UNIQUE_ID', 'COUNTYFP', 'COUNTYNM', 'PRECINCT', 'PRECCODE', 'VTDST22']+\n",
    "                                     list(pber_all_updated.columns[(pber_all_updated.columns.str.slice(start=-2, stop=-1)!=\"_\")&\n",
    "                                                                    (pber_all_updated.columns.str.startswith(\"G\"))])+[\"geometry\"]]\n",
    "export_import_test(pber_all, pber_all_format, oh_blocks)\n",
    "\n",
    "\n",
    "#STATEWIDE\n",
    "pber_st_updated = fix_self_intersection(pber_st, oh_blocks)\n",
    "pber_st_format = pber_st_updated[['UNIQUE_ID', 'COUNTYFP', 'COUNTYNM', 'PRECINCT', 'PRECCODE', 'VTDST22']+\n",
    "                                     list(pber_st_updated.columns[(pber_st_updated.columns.str.slice(start=-2, stop=-1)!=\"_\")&\n",
    "                                                                    (pber_st_updated.columns.str.startswith(\"G\"))])+[\"geometry\"]]\n",
    "export_import_test(pber_st, pber_st_format, oh_blocks)\n",
    "\n",
    "\n",
    "#CONGRESSIONAL\n",
    "pber_cong_updated = fix_self_intersection(pber_cong, oh_blocks)\n",
    "#pber_cong_updated[\"CON_DIST\"] = pber_cong_updated[\"CONG_DIST\"]\n",
    "pber_cong_format = pber_cong_updated[['UNIQUE_ID', 'COUNTYFP', 'COUNTYNM', 'PRECINCT', 'PRECCODE', 'VTDST22', 'CONG_DIST']+\n",
    "                                     list(pber_cong_updated.columns[(pber_cong_updated.columns.str.slice(start=-2, stop=-1)!=\"_\")&\n",
    "                                                                    (pber_cong_updated.columns.str.startswith(\"G\"))])+[\"geometry\"]]\n",
    "export_import_test(pber_cong, pber_cong_format, oh_blocks)\n",
    "\n",
    "\n",
    "#SLDL\n",
    "pber_sl_updated = fix_self_intersection(pber_sl, oh_blocks)\n",
    "pber_sl_format = pber_sl_updated[['UNIQUE_ID', 'COUNTYFP', 'COUNTYNM', 'PRECINCT', 'PRECCODE','VTDST22', 'SLDL_DIST']+\n",
    "                list(pber_sl_updated.columns[(pber_sl_updated.columns.str.slice(start=-2, stop=-1)!=\"_\")&\n",
    "                                             (pber_sl_updated.columns.str.startswith(\"G\"))])+[\"geometry\"]]\n",
    "export_import_test(pber_sl, pber_sl_format, oh_blocks)\n",
    "\n",
    "\n",
    "#SLDU\n",
    "pber_su_updated = fix_self_intersection(pber_su, oh_blocks)\n",
    "pber_su_format = pber_su_updated[['UNIQUE_ID', 'COUNTYFP', 'COUNTYNM', 'PRECINCT', 'PRECCODE', 'VTDST22', 'SLDU_DIST']+\n",
    "                                 list(pber_su_updated.columns[(pber_su_updated.columns.str.slice(start=-2, stop=-1)!=\"_\")&\n",
    "                                                              (pber_su_updated.columns.str.startswith(\"G\"))])+[\"geometry\"]]\n",
    "export_import_test(pber_su, pber_su_format, oh_blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7d921a-1a4e-474d-89a1-a1800bca3db3",
   "metadata": {},
   "source": [
    "## Check vote totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98217148-8d4b-4fd9-bed1-9e5d5ed4ce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_unique_id_unique(merged_gdf):\n",
    "    assert merged_gdf[\"UNIQUE_ID\"].isna().any()==False\n",
    "    assert merged_gdf[\"UNIQUE_ID\"].nunique()==merged_gdf.shape[0]\n",
    "    return \"unique_id is unique\"\n",
    "\n",
    "\n",
    "#State, County, Precinct total vote checks adapted from pdv checks: https://github.com/nonpartisan-redistricting-datahub/pdv-resources/blob/main/pdv_functions.py\n",
    "def statewide_totals_check(partner_df, partner_name, source_df, source_name, column_list):\n",
    "    \"\"\"Compares the totals of two election result dataframes at the statewide total level\n",
    "\n",
    "    Args:\n",
    "      partner_df: DataFrame of election results we are comparing against\n",
    "      source_df: DataFrame of election results we are comparing to\n",
    "      column_list: List of races that there are votes for\n",
    " \n",
    "    Returns:\n",
    "      difference list\n",
    "    \"\"\"\n",
    "    print(\"***Statewide Totals Check***\")\n",
    "    diff_races=[]\n",
    "    for race in column_list:\n",
    "        if (partner_df[race].sum()- source_df[race].sum() != 0):\n",
    "            if race not in diff_races:\n",
    "                diff_races.append(race)\n",
    "            print(race+\" has a difference of \"+str(partner_df[race].sum()-source_df[race].sum())+\" votes\")\n",
    "            print(\"\\t\"+ partner_name + \": \"+str(partner_df[race].sum())+\" votes\")\n",
    "            print(\"\\t\"+ source_name +\": \"+str(source_df[race].sum())+\" votes\")\n",
    "        #else:\n",
    "            #print(race + \" is equal\", \"\\t both dataframes \" + str(partner_df[race].sum()))\n",
    "    \n",
    "    if (len(diff_races)==0):\n",
    "        print(\"All contests match statewide!\")\n",
    "    elif (len(diff_races)>0):\n",
    "        print(\"Contests with differences: \")\n",
    "    \n",
    "    return diff_races\n",
    "\n",
    "\n",
    "def county_totals_check(partner_df, partner_name, source_df, source_name, column_list,county_col,full_print=False):\n",
    "    \"\"\"Compares the totals of two election result dataframes at the county level\n",
    "\n",
    "    Args:\n",
    "      partner_df: DataFrame of election results we are comparing against\n",
    "      partner_name: String of what to call the partner in the print statement\n",
    "      source_df: DataFrame of election results we are comparing to\n",
    "      source_name: String of what to call the source in the print statement\n",
    "      column_list: List of races that there are votes for\n",
    "      county_col: String of the column name that contains county information\n",
    "      full_print: Boolean specifying whether to print out everything, including counties w/ similarities\n",
    "\n",
    "    Returns:\n",
    "      difference list\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n***Countywide Totals Check***\")\n",
    "    diff_counties=[]\n",
    "    for race in column_list:\n",
    "        diff = partner_df.groupby([county_col]).sum()[race]-source_df.groupby([county_col]).sum()[race]\n",
    "        for val in diff[diff != 0].index.values.tolist():\n",
    "            if val not in diff_counties:\n",
    "                diff_counties.append(val)\n",
    "        if len(diff[diff != 0]!=0):   \n",
    "            print(race + \" contains differences in these counties:\")\n",
    "            for val in diff[diff != 0].index.values.tolist():\n",
    "                county_differences = diff[diff != 0]\n",
    "                print(\"\\t\"+val+\" has a difference of \"+str(county_differences[val])+\" votes\")\n",
    "                print(\"\\t\\t\"+ partner_name + \": \"+str(partner_df.groupby([county_col]).sum().loc[val,race])+\" votes\")\n",
    "                print(\"\\t\\t\"+ source_name +\": \"+str(source_df.groupby([county_col]).sum().loc[val,race])+\" votes\")\n",
    "            if (full_print):\n",
    "                for val in diff[diff == 0].index.values.tolist():\n",
    "                    county_similarities = diff[diff == 0]\n",
    "                    print(\"\\t\"+val + \": \"+ str(partner_df.groupby([county_col]).sum().loc[val,race])+\" votes\")\n",
    "        #else:\n",
    "            #print(race + \" is equal across all counties\")\n",
    "            #if (full_print):\n",
    "               # for val in diff[diff == 0].index.values.tolist():\n",
    "                 #   county_similarities = diff[diff == 0]\n",
    "                    #print(\"\\t\"+val + \": \"+ str(partner_df.groupby([county_col]).sum().loc[val,race])+\" votes\")\n",
    "    if (len(diff_counties)==0):\n",
    "        print(\"All contests in all counties match!\")\n",
    "    elif (len(diff_counties)>0):\n",
    "        print(\"Counties with differences: \")\n",
    "        \n",
    "    return diff_counties\n",
    "        \n",
    "    \n",
    "def precinct_votes_check(merged_df,column_list,vest_on_left,name_col,print_level=0):\n",
    "    \"\"\"Checks a merged dataframe with two election results at the precinct level\n",
    "\n",
    "    Args:\n",
    "      merged_df: DataFrame with one set of election results joined to another\n",
    "      column_list: List of races that there are votes for\n",
    "      vest_on_left: Boolean specifying whether VEST data is on the left side of merged_df\n",
    "      name_col: String of the column name to refer to precincts when a difference occurs\n",
    "      print_level: Integer that specifies how large the vote difference in a precinct must be to be printed\n",
    "\n",
    "    Returns:\n",
    "      list of differences\n",
    "    \"\"\"\n",
    "    print(\"\\n***Precinct Totals Check***\")\n",
    "    merged_df = merged_df.sort_values(by=[name_col],inplace=False)\n",
    "    matching_rows = 0\n",
    "    different_rows = 0\n",
    "    diff_list=[]\n",
    "    diff_values = []\n",
    "    max_diff = 0\n",
    "    for index,row in merged_df.iterrows():\n",
    "        same = True\n",
    "        for i in column_list:\n",
    "            left_data = i + \"_x\"\n",
    "            right_data = i + \"_y\"\n",
    "            \n",
    "            if ((row[left_data] is None) or (row[right_data] is None) or (np.isnan(row[right_data])or(np.isnan(row[left_data])))):\n",
    "                print(\"FIX NaN value at: \", row[name_col])\n",
    "            \n",
    "            diff = abs(row[left_data]-row[right_data])\n",
    "            if (diff>0):\n",
    "                same = False\n",
    "                diff_values.append(abs(diff))\n",
    "                if (diff>max_diff):\n",
    "                    max_diff = diff\n",
    "            if(diff>print_level):\n",
    "                if (vest_on_left):\n",
    "                    print(i, \"{:.>72}\".format(row[name_col]), \"(V)\",\"{:.>5}\".format(int(row[left_data])),\" (S){:.>5}\".format(int(row[right_data])),\"(D):{:>5}\".format(int(row[left_data]-row[right_data])))                           \n",
    "                else:\n",
    "                    print(i, \"{:.>72}\".format(row[name_col]), \"(S)\",\"{:.>5}\".format(int(row[left_data])),\" (V){:.>5}\".format(int(row[right_data])),\"(D):{:>5}\".format(int(row[left_data]-row[right_data])))\n",
    "        if(same != True):\n",
    "            different_rows +=1\n",
    "            diff_list.append(row[name_col])\n",
    "        else:\n",
    "            matching_rows +=1\n",
    "\n",
    "    print(\"\\nThere are \", len(merged_df.index),\" total rows\")\n",
    "    \n",
    "    if(len(diff_values)!=0):\n",
    "        print(matching_rows,\" of these rows are the same\")\n",
    "        print(\"\\nAll precincts containing differences:\")\n",
    "        print(\"The average difference is: \", str(sum(diff_values)/len(diff_values)))\n",
    "        print(\"\\nThe max difference between any one shared column in a row is: \", max_diff)\n",
    "        count_big_diff = len([i for i in diff_values if i > 10])\n",
    "        print(\"There are \", str(count_big_diff), \"precinct results with a difference greater than 10\")\n",
    "    else:\n",
    "        print(matching_rows,\" of these rows are the same\")\n",
    "    \n",
    "    diff_list.sort()\n",
    "    \n",
    "    return diff_list\n",
    "\n",
    "\n",
    "def run_all_checks(partner_df, partner_name, source_df, source_name, county_col,full_print=False, prec_check=True):\n",
    "    column_list = list(source_df.columns[source_df.columns.str.startswith(\"G\")])\n",
    "    check_unique_id_unique(source_df)\n",
    "    #Running inner join because of expected nan value for ZZZ precincts\n",
    "    merged_df = pd.merge(source_df, partner_df, on = [\"UNIQUE_ID\"], how = \"inner\", indicator=True)\n",
    "    vest_on_left = False\n",
    "    name_col = \"UNIQUE_ID\"\n",
    "    #All matches statewide and county levels\n",
    "    statewide_totals_check(partner_df, partner_name, source_df, source_name, column_list)\n",
    "    #County total check not working here but also not needed if others work...\n",
    "    #county_totals_check(partner_df, partner_name, source_df, source_name, column_list,county_col,full_print=False)\n",
    "    if prec_check ==True:\n",
    "        precinct_votes_check(merged_df,column_list,vest_on_left,name_col,print_level=0)\n",
    "    \n",
    "    \n",
    "\n",
    "partner_name = \"original ER 22\"\n",
    "source_name = \"PBER 22\"\n",
    "county_col = \"COUNTYNM\"\n",
    "#---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbe04a26-29d6-4c03-abee-20b4176904b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pber_all_format = pber_all_updated[['UNIQUE_ID', 'COUNTYFP', 'COUNTYNM', 'PRECINCT', 'PRECCODE', 'VTDST22']+\n",
    "                                     list(pber_all_updated.columns[(pber_all_updated.columns.str.slice(start=-2, stop=-1)!=\"_\")&\n",
    "                                                                    (pber_all_updated.columns.str.startswith(\"G\"))])+[\"geometry\"]]\n",
    "\n",
    "pber_st_format = pber_st_updated[['UNIQUE_ID', 'COUNTYFP', 'COUNTYNM', 'PRECINCT', 'PRECCODE', 'VTDST22']+\n",
    "                                     list(pber_st_updated.columns[(pber_st_updated.columns.str.slice(start=-2, stop=-1)!=\"_\")&\n",
    "                                                                    (pber_st_updated.columns.str.startswith(\"G\"))])+[\"geometry\"]]\n",
    "\n",
    "pber_cong_updated[\"CON_DIST\"] = pber_cong_updated[\"CONG_DIST\"]\n",
    "pber_cong_format = pber_cong_updated[['UNIQUE_ID', 'COUNTYFP', 'COUNTYNM', 'PRECINCT', 'PRECCODE', 'VTDST22', 'CON_DIST']+\n",
    "                                     list(pber_cong_updated.columns[(pber_cong_updated.columns.str.slice(start=-2, stop=-1)!=\"_\")&\n",
    "                                                                    (pber_cong_updated.columns.str.startswith(\"G\"))])+[\"geometry\"]]\n",
    "\n",
    "pber_sl_format = pber_sl_updated[['UNIQUE_ID', 'COUNTYFP', 'COUNTYNM', 'PRECINCT', 'PRECCODE','VTDST22', 'SLDL_DIST']+\n",
    "                list(pber_sl_updated.columns[(pber_sl_updated.columns.str.slice(start=-2, stop=-1)!=\"_\")&\n",
    "                                             (pber_sl_updated.columns.str.startswith(\"G\"))])+[\"geometry\"]]\n",
    "\n",
    "pber_su_format = pber_su_updated[['UNIQUE_ID', 'COUNTYFP', 'COUNTYNM', 'PRECINCT', 'PRECCODE', 'VTDST22', 'SLDU_DIST']+\n",
    "                                 list(pber_su_updated.columns[(pber_su_updated.columns.str.slice(start=-2, stop=-1)!=\"_\")&\n",
    "                                                              (pber_su_updated.columns.str.startswith(\"G\"))])+[\"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c48dfc50-ddf4-4120-8297-9fb8cf0492eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "checking statewide gdf:\n",
      "***Statewide Totals Check***\n",
      "All contests match statewide!\n",
      "\n",
      "***Precinct Totals Check***\n",
      "\n",
      "There are  8941  total rows\n",
      "8941  of these rows are the same\n",
      "\n",
      "checking statewide gdf:\n",
      "***Statewide Totals Check***\n",
      "All contests match statewide!\n",
      "\n",
      "***Precinct Totals Check***\n",
      "\n",
      "There are  8941  total rows\n",
      "8941  of these rows are the same\n",
      "\n",
      "checking CONG w splits gdf:\n",
      "***Statewide Totals Check***\n",
      "All contests match statewide!\n",
      "\n",
      "***Precinct Totals Check***\n",
      "\n",
      "There are  8977  total rows\n",
      "8977  of these rows are the same\n",
      "\n",
      "checking SLDL w splits gdf:\n",
      "***Statewide Totals Check***\n",
      "All contests match statewide!\n",
      "\n",
      "***Precinct Totals Check***\n",
      "\n",
      "There are  9068  total rows\n",
      "9068  of these rows are the same\n",
      "\n",
      "checking SLDU w splits gdf\n",
      "***Statewide Totals Check***\n",
      "All contests match statewide!\n",
      "\n",
      "***Precinct Totals Check***\n",
      "\n",
      "There are  8970  total rows\n",
      "8970  of these rows are the same\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nchecking statewide gdf:\")\n",
    "run_all_checks(pber_all, partner_name, pber_all_format, \"merge gdf\",county_col,full_print=False, prec_check=True)\n",
    "print(\"\\nchecking statewide gdf:\")\n",
    "run_all_checks(pber_st, partner_name, pber_st_format, \"merge gdf\", county_col,full_print=False, prec_check=True)\n",
    "print(\"\\nchecking CONG w splits gdf:\")\n",
    "run_all_checks(pber_cong, partner_name, pber_cong_format.reset_index(), \"cong split\",county_col,full_print=False, prec_check=True)\n",
    "print(\"\\nchecking SLDL w splits gdf:\")\n",
    "run_all_checks(pber_sl, partner_name, pber_sl_format, \"sl split\",county_col,full_print=False, prec_check=True)\n",
    "print(\"\\nchecking SLDU w splits gdf\")\n",
    "run_all_checks(pber_su, partner_name, pber_su_format, \"su split\",county_col,full_print=False, prec_check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264b316f-8a0d-4ef3-8cef-033fa1e0ae3d",
   "metadata": {},
   "source": [
    "## Export cleaned gdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e20691d9-bfdc-4e3b-b68b-888f278a7922",
   "metadata": {},
   "outputs": [],
   "source": [
    "pber_all_format.to_file(\"./oh_2022_gen_prec_shp/oh_2022_gen_prec_no_splits.shp\")\n",
    "pber_st_format.to_file(\"./oh_2022_gen_prec_shp/oh_2022_gen_prec_st.shp\")\n",
    "pber_cong_format.to_file(\"./oh_2022_gen_prec_shp/oh_2022_gen_prec_cong.shp\")\n",
    "pber_su_format.to_file(\"./oh_2022_gen_prec_shp/oh_2022_gen_prec_sldu.shp\")\n",
    "pber_sl_format.to_file(\"./oh_2022_gen_prec_shp/oh_2022_gen_prec_sldl.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f51c5c-e1e4-4d33-a89d-57a7103686cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdv_env",
   "language": "python",
   "name": "pdv_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
